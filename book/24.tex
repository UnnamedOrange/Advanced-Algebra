% Licensed under the Creative Commons Attribution Share Alike 4.0 International.
% See the LICENCE file in the repository root for full licence text.

\section{矩阵的相似}

矩阵的相似是本笔记中最重要的内容之一，其研究动力如下。为了求 $n$ 级矩阵 $A$ 的方幂 $A^m$，如果能找到 $n$ 级可逆矩阵 $P$，使得 $P^{-1} AP = D$，其中 $D$ 是对角矩阵，那么 $A = PDP^{-1}$，从而 $A^m = PD^m P^{-1}$，而对角矩阵 $D$ 的方幂很容易计算，于是 $A^m$ 也就比较容易算出了。据此，我们定义相似的概念。

\subsection{相似的概念}

\begin{definition}{相似}
	设 $A$ 与 $B$ 都是数域 $K$ 上的 $n$ 级矩阵，如果存在数域 $\mathbb K$ 上一个 $n$ 级可逆矩阵 $P$，使得 $P^{-1} A P = B$，那么称 $A$ 与 $B$ 是\emph{相似}的，记作 $A \sim B$。
\end{definition}

\begin{theorem}
	相似是一个等价关系。
\end{theorem}

\begin{definition}{相似类}
	在相似关系下，$A$ 的等价类称为 $A$ 的\emph{相似类}。
\end{definition}

容易证明，矩阵的相似满足以下性质。

\begin{theorem}[相似的运算性质]
	如果 $B_1 = P^{-1} A_1 P$，$B_2 = P^{-1} A_2 P$，$m$ 是正整数，那么：
	\begin{enumerate}
		\item $B_1 + B_2 = P^{-1} (A_1 + A_2) P$。
		\item $B_1 B_2 = P^{-1} (A_1 A_2) P$。
		\item $B_1^m = P^{-1} A_1^m P$。
	\end{enumerate}
\end{theorem}

\begin{theorem}
	相似的矩阵的行列式是一个不变量，但不是完全不变量。
\end{theorem}

\begin{theorem}
	相似的矩阵或者都可逆，或者都不可逆；当它们可逆时，它们的逆矩阵也相似。
\end{theorem}

\begin{theorem}
	相似的矩阵的秩是一个不变量，但不是完全不变量。
\end{theorem}

下面我们提出矩阵的迹的概念，并证明相似的矩阵的迹也是一个不变量。

\begin{definition}{迹}
	$n$ 级矩阵 $A = (a_{ij})$ 的主对角线上的元素之和称为 $A$ 的\emph{迹}，记作 $\operatorname{tr}(A)$， 即 $\operatorname{tr}(A) = a_{11} + a_{22} + \cdots + a_{nn}$。
\end{definition}

\begin{theorem}[矩阵的迹的运算性质]
	\begin{enumerate}
		\item 对 $n$ 级矩阵，$\operatorname{tr}(A + B) = \operatorname{tr}(A) + \operatorname{tr}(B)$。
		\item 对 $n$ 级矩阵，$\operatorname{tr}(kA) = k \operatorname{tr}(A)$。
		\item 对 $n \times m$ 矩阵 $A$ 和 $m \times n$ 矩阵 $B$，$\operatorname{tr}(AB) = \operatorname{tr}(BA)$。
	\end{enumerate}
\end{theorem}

\begin{proof}[只证明 3.]
	$$
	\begin{aligned}
		\operatorname{tr}(AB) &= \sum\limits_{i = 1}^n (AB)(i; i)
		\\&=
		\sum\limits_{i = 1}^n \sum\limits_{k = 1}^m a_{ik} b_{ki}
		\\&=
		\sum\limits_{k = 1}^m \sum\limits_{i = 1}^n b_{ki} a_{ik}
		\\&=
		\sum\limits_{k = 1}^m (BA)(k;k) = \operatorname{tr}(BA)
	\end{aligned}
	$$
\end{proof}

可见，矩阵的迹是从矩阵乘法的非交换性中提取的可交换的量。

\begin{theorem}
	相似的矩阵有相等的迹。
\end{theorem}

\begin{proof}
	$$
	\operatorname{tr}(B) = \operatorname{tr}(P^{-1} A P) = \operatorname{tr}(APP^{-1}) = \operatorname{tr}(A)
	$$
\end{proof}

综合以上定理，我们总结出相似不变量的概念。

\begin{definition}{相似不变量}
	矩阵的行列式、秩、迹都是相似关系下的不变量，简称为\emph{相似不变量}。
\end{definition}

% TODO: 补充例题。

\subsection{矩阵可对角化的概念}

\begin{definition}{可对角化}
	如果 $n$ 级矩阵 $A$ 能够相似于一个对角矩阵，那么称 $A$ \emph{可对角化}。
\end{definition}

我们直接给出矩阵可对角化的充分必要条件。

\begin{theorem}[矩阵可对角化的充分必要条件]
	数域 $\mathbb K$ 上 $n$ 级矩阵 $A$ 可对角化的充分必要条件是，$\mathbb K^n$ 中有 $n$ 个线性无关的列向量 $\vec \alpha_1, \ldots, \vec \alpha_n$，以及 $\mathbb K$ 中有 $n$ 个数 $\lambda_1, \ldots, \lambda_n$（它们之中可能相等），使得 $A \vec \alpha_i = \lambda_i \vec \alpha_i \pod{i = 1, \ldots, n}$。这时，令 $P = \begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_n \end{bmatrix}$，则 $P^{-1} AP = \operatorname{diag} \{ \lambda_1, \ldots, \lambda_n \}$。
\end{theorem}

\begin{proof}
	设 $D = \operatorname{diag} \{ \lambda_1, \ldots, \lambda_n \}$，则以下命题互为充分必要条件：

	\begin{itemize}
		\item $A$ 相似于一个对角矩阵，即 $P^{-1} AP = D$。
		\item $AP = PD$，设 $P = \begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_n \end{bmatrix}$。
		\item $\begin{bmatrix} A \vec \alpha_1 & \cdots & A \vec \alpha_n \end{bmatrix} =  \begin{bmatrix} \lambda_1 \vec \alpha_1 & \cdots & \lambda_n \vec \alpha_n \end{bmatrix}$
		\item $A \vec \alpha_i = \lambda_i \vec \alpha_i \pod{i = 1, \ldots, n}$，其中 $\vec \alpha_1, \cdots, \vec \alpha_n$ 线性无关。
	\end{itemize}
\end{proof}

\subsection{特征多项式}

根据以上关于矩阵可对角化的分析，我们可以提出以下概念。

\begin{definition}{特征值,特征向量}
	设 $A$ 是数域 $\mathbb K$ 上的 $n$ 级矩阵，如果 $\mathbb K^n$ 中有非零列向量 $\vec \alpha$，使得 $A \vec \alpha = \lambda_0 \vec \alpha \pod{\lambda_0 \in \mathbb K}$，那么称 $\lambda_0$ 是 $A$ 的一个\emph{特征值}，称 $\vec \alpha$ 是 $A$ 的属于特征值 $\lambda_0$ 的一个\emph{特征向量}。
\end{definition}

注意，根据定义，零向量不是 $A$ 的特征向量。

关于特征值与特征向量，我们首先给出以下显然的结论。

\begin{theorem}
	如果 $\vec \alpha$ 是 $A$ 的属于 $\lambda_0$ 的一个特征向量，那么对于任意 $k \in \mathbb K \pod{k \ne 0}$，$k \vec \alpha$ 也是 $A$ 的属于 $\lambda_0$ 的特征向量。
\end{theorem}

\begin{proof}
	$$
	A(k \vec \alpha) = k(A \vec \alpha) = k(\lambda_0 \vec \alpha) = \lambda_0 (k \vec \alpha)
	$$
\end{proof}

根据以上定义，又受可对角化的充分必要条件的推导过程启发，我们可知以下命题互为充分必要条件：

\begin{itemize}
	\item $\lambda_0$ 是 $A$ 的一个特征值，$\vec \alpha$ 是 $A$ 的属于 $\lambda_0$ 的一个特征向量。
	\item $A \vec \alpha = \lambda_0 \vec \alpha \pod{\vec \alpha \ne \vec 0, \lambda_0 \in \mathbb K}$
	\item $(\lambda_0 I - A) \vec \alpha = \vec 0 \pod{\vec \alpha \ne \vec 0, \lambda_0 \in \mathbb K}$
	\item $\vec \alpha$ 是齐次线性方程组 $(\lambda_0 I - A) \vec x = \vec 0$ 的一个非零解（$\lambda_0 \in \mathbb K$）。
	\item $|\lambda_0 I - A| = 0$，$\vec \alpha$ 是 $(\lambda_0 I - A) \vec x = \vec 0$ 的一个非零解（$\lambda_0 \in \mathbb K$）。
	\item $\lambda_0$ 是\textbf{多项式} $|\lambda I - A|$ 在 $\mathbb K$ 中的一个根，$\vec \alpha$ 是 $(\lambda_0 I - A) \vec x = \vec 0$ 的一个非零解。
\end{itemize}

将行列式 $|\lambda I - A|$ 的完全展开式看作一个关于 $\lambda$ 的多项式，即得到了上文中的多项式 $|\lambda I - A|$。
$$
|\lambda I - A| =
\begin{vmatrix}
\lambda - a_{11} & -a_{12} & \cdots & -a_{1n}
\\
-a_{21} & \lambda - a_{22} & \cdots & -a_{2n}
\\
\vdots & \vdots & & \vdots
\\
-a_{n1} & -a_{n2} & \cdots & \lambda - a_{nn}
\end{vmatrix}
$$

\begin{definition}{特征多项式}
	把 $|\lambda I - A|$ 称为 $A$ 的\emph{特征多项式}。
\end{definition}

以下定理描述了多项式 $|\lambda I - A|$ 的结构。

\begin{theorem}
	设 $A$ 是数域 $\mathbb K$ 上的 $n$ 级矩阵，则 $A$ 的特征多项式 $|\lambda I - A|$ 是一个 $n$ 次多项式，$\lambda^n$ 的系数是 $1$，$\lambda^{n - 1}$ 的系数等于 $-\operatorname{tr}(A)$，常数项为 $(-1)^n |A|$，$\lambda^{n - k}$ 的系数为 $A$ 的所有 $k$ 阶主子式的和乘以 $(-1)^k \pod{1 \le k < n}$。
\end{theorem}

\begin{proof}
	设 $A = (a_{ij})$ 的列向量组是 $\vec \alpha_1, \ldots, \vec \alpha_n$，写出 $|\lambda I - A|$：
	$$
	|\lambda I - A| =
	\begin{vmatrix} \lambda \vec e_1 - \vec \alpha_1 & \lambda \vec e_2 - \vec \alpha_2 & \cdots & \lambda \vec e_n - \vec \alpha_n \end{vmatrix}
	$$
	利用行列式的多线性，$|\lambda I - A|$ 可以拆成 $2^n$ 个行列式的和，我们把它按全是 $\vec e$，全是 $\vec \alpha$，既有 $\vec e$ 又有 $\vec \alpha$ 分成三类。

	第一类，显然这个行列式等于 $\lambda^n$。第二类，显然这个行列式等于 $(-1)^n |A|$。对于第三类行列式，设第 $j_1, j_2, \ldots, j_{n - k}$ 列是 $\vec e$，于是可以将这个行列式按第 $j_1, j_2, \ldots, j_{n - k}$ 列展开。这 $n - k$ 列元素组成的 $n - k$ 阶子式只有一个不为 $0$，即选出第 $j_1, \ldots, j_{n - k}$ 行的那一个不为 $0$，还可知这个 $n - k$ 阶子式就是 $|\lambda I_{n - k}| = \lambda^{n - k}$。而剩下的 $k$ 阶子式对应的代数余子式为：
	$$
	(-1)^{(j_1 + \cdots + j_k) + (j_1 + \cdots + j_k)} (-A) \begin{pmatrix} j'_1, \ldots, j'_k \\ j'_1, \ldots, j'_k \end{pmatrix} = (-1)^k A \begin{pmatrix} j'_1, \ldots, j'_k \\ j'_1, \ldots, j'_k \end{pmatrix}
	$$

	于是第三类行列式的值为：$(-1)^k A \begin{pmatrix} j'_1, \ldots, j'_k \\ j'_1, \ldots, j'_k \end{pmatrix} \lambda^{n - k}$。特别地，当 $k = 1$ 时，得 $\lambda^{n - 1}$ 的系数为 $-\operatorname{tr}(A)$。综上，可以写出 $\lambda^{n - k}$ 的系数，即可得到 $A$ 的特征多项式的系数表示形式。
	$$
	\lambda^n - \operatorname{tr}(A) + \cdots + (-1)^k \sum\limits_{1 \le j'_1 < \cdots < j'_k \le n} A \begin{pmatrix} j'_1, \ldots, j'_k \\ j'_1, \ldots, j'_k \end{pmatrix} \lambda^{n - k} + \cdots + (-1)^n |A|
	$$
\end{proof}

由代数学基本定理，复数域上的特征多项式亦可用以下定理所示的形式表示。

\begin{theorem}
	设 $A \in M_n (\C)$，则 $A$ 的特征多项式为：
	$$
	|\lambda I - A| = (\lambda - \lambda_1) (\lambda - \lambda_2) \cdots (\lambda - \lambda_n)
	$$
	其中 $\lambda_1, \ldots, \lambda_n$ 是 $A$ 的特征值（可重）。

	$A$ 的特征多项式亦可记作：
	$$
	|\lambda I - A| = (\lambda - \lambda_1)^{l_1} (\lambda - \lambda_2)^{l_2} \cdots (\lambda - \lambda_m)^{l_m}
	$$
	其中 $\lambda_1, \ldots, \lambda_m$ 是 $A$ 的特征值（互不相同）。
\end{theorem}

综合以上两个定理，可知复数域上的矩阵的所有 $k$ 阶主子式之和满足以下性质。

\begin{theorem}
	设 $A \in M_n(\C)$，设 $A$ 的特征值为 $\lambda_1, \lambda_2, \ldots, \lambda_n$（可重），则 $A$ 的所有 $k$ 阶主子式之和为 $\sum\limits_{1 \le j_1 < \cdots < j_{n - k} \le n} \lambda_{j_1} \cdots \lambda_{j_{n - k}}$。
\end{theorem}

\begin{proof}
	设 $A$ 的所有 $k$ 阶主子式之和为 $A_k$。由于 $\lambda^{n - k}$ 的系数为 $(-1)^k A_k$，又等于 $(-1)^k \sum\limits_{1 \le j_1 < \cdots < j_{n - k} \le n} \lambda_{j_1} \cdots \lambda_{j_{n - k}}$。即可知 $A_k = \sum\limits_{1 \le j_1 < \cdots < j_{n - k} \le n} \lambda_{j_1} \cdots \lambda_{j_{n - k}}$。
\end{proof}

之所以特征多项式可以作为矩阵的一个特征，是因为相似的矩阵有相等的特征多项式。

\begin{theorem}
	相似的矩阵有相等的特征多项式。
\end{theorem}

\begin{proof}
	设 $A \sim B$，则有可逆矩阵 $P$，使得 $B = P^{-1} A P$，于是：
	$$
	|\lambda I - B| = |\lambda I - P^{-1} A P| = |P^{-1} (\lambda I - A) P| = |P^{-1}| |\lambda I - A||P| = |\lambda I - A|
	$$
\end{proof}

\subsection{特征值的性质}

在研究了特征多项式的结构后，本节中将提出几个有关特征值的定理。

\begin{theorem}
	相似的矩阵有完全相同的特征值。
\end{theorem}

\begin{theorem}
	若 $A$ 可逆，则零不可能是 $A$ 的一个特征值。
\end{theorem}

\begin{proof}
	假设零是 $A$ 的一个特征值，则 $A$ 的行列式为 $0$，与 $A$ 可逆矛盾。
\end{proof}

\begin{theorem}
	$\lambda_0$ 为可逆矩阵 $A \in M_n(\C)$ 的特征值的充分必要条件是 $\dfrac{1}{\lambda_0}$ 为 $A^{-1}$ 的特征值。
\end{theorem}

\begin{proof}
	设 $|\lambda I - A| = (\lambda - \lambda_0)^{l_0} (\lambda - \lambda_1)^{l_1} \cdots (\lambda - \lambda_m)^{l_m}$，由代数学基本定理，$l_0 + \cdots + l_m = n$。

	考虑计算 $A^{-1}$ 的特征多项式，尝试从 $|\lambda I - A^{-1}|$ 化出 $|\lambda I - A|$ 的形式以展开成多项式。
	$$
	\begin{aligned}
		|\lambda I - A^{-1}| &= |\lambda A A^{-1} - A^{-1}| = |A^{-1}| |\lambda A - I| = (-\lambda)^n |A^{-1}| \biggl| \dfrac{1}{\lambda} I - A \biggr|
		\\&=
		(-\lambda)^n |A^{-1}| \biggl( \dfrac{1}{\lambda} - \lambda_0 \biggr)^{l_0} \cdots \biggl( \dfrac{1}{\lambda} - \lambda_m \biggr)^{l_m}
		\\&=
		|A^{-1}||A| \biggl( \lambda - \dfrac{1}{\lambda_0} \biggr)^{l_0} \cdots \biggl( \lambda - \dfrac{1}{\lambda_m} \biggr)^{l_m}
		\\&=
		\biggl( \lambda - \dfrac{1}{\lambda_0} \biggr)^{l_0} \cdots \biggl( \lambda - \dfrac{1}{\lambda_m} \biggr)^{l_m}
	\end{aligned}
	$$
\end{proof}

\begin{theorem}
	设 $A \in M_n(\C)$，$f(x) = \sum\limits_{i = 0}^s a_i x^i$。若 $A$ 的特征值为 $\lambda_1, \ldots, \lambda_n$（可重），则 $f(A)$ 的特征值为 $f(\lambda_1), \ldots, f(\lambda_n)$。同时，若 $f(A)$ 的特征值为 $\lambda_1, \ldots, \lambda_n$，则对每个 $\lambda_i$，都存在一个 $q$，使得 $f(q) = \lambda_i$，并且 $q$ 是 $A$ 的特征值。
\end{theorem}

\begin{proof}
	由于 $\lambda_1, \ldots, \lambda_n$ 为 $A$ 的特征值，故设 $\vec \alpha_i \in \C^n$ 为 $\lambda_i$ 对应的特征向量，即有 $A \vec \alpha_i = \lambda_i \vec \alpha_i$。

	考虑左乘一个 $A$，得 $A^2 \vec \alpha_i = A \cdot A \vec \alpha_i = A (\lambda_i \vec \alpha_i) = \lambda_i (A \vec \alpha_i) = \lambda_i^2 \vec \alpha_i$。同理归纳知，$A^m \vec \alpha_i = \lambda_i^m \vec \alpha_i$，从而有 $(a_m A^m) \vec \alpha_i = (a_m \lambda_i^m) \vec \alpha_i$。于是可以通过相加得 $f(A) \vec \alpha_i = f(\lambda_i) \vec \alpha_i$。即证得：若 $A$ 的特征值为 $\lambda_1, \cdots, \lambda_n$，则 $f(A)$ 的特征值为 $f(\lambda_1), \cdots, f(\lambda_n)$，并且 $A$ 的特征值 $\lambda_i$ 对应的特征子空间与 $f(A)$ 的特征值 $f(\lambda_i)$ 对应的特征子空间相等。

	\bigskip

	由于 $\lambda_1, \ldots, \lambda_n$ 为 $f(A)$ 的特征值，故设 $\vec v_i \in \C^n$ 为 $\lambda_i$ 对应的特征向量，即有 $f(A) \vec v_i = \lambda_i \vec v_i$。

	设 $f(x) - \lambda_i = C(x - q_1) \cdots (x - q_s)$（注意，这是一个 $s$ 次多项式，在 $\C$ 上一定有 $s$ 个解），则 $\lambda_i = f(q_j) \pod{1 \le j \le s}$。要证明原命题，只需证明：$\exists j \in \{1, 2, \cdots, s\}$，使得 $q_j$ 是 $A$ 的特征值。

	同时，由 $f(x) - \lambda_i$ 的分解，可知 $(A - q_1 I) \cdots (A - q_s I) \vec v_i = \vec 0$。注意到，若 $(A - q_2 I) \cdots (A - q_s I) \vec v_i \ne \vec 0$，则 $(A - q_2 I) \cdots (A - q_s I) \vec v_i$ 是 $A$ 的一个特征向量，对应特征值为 $q_1$，此时结论成立。

	否则，若 $(A - q_3 I) \cdots (A - q_s I) \vec v_i \ne \vec 0$，则 $(A - q_3 I) \cdots (A - q_s I) \vec v_i$ 是 $A$ 的一个特征向量，对应特征值为 $q_2$，此时结论成立。

	否则，继续照此进行检查，直到结论成立。最后一个式子可能是 $(A - q_s I) \vec v_i = \vec 0$，由于 $\vec v_i \ne \vec 0$，故在该情况下一定可以得出结论：$\vec v_i$ 是 $A$ 的一个特征向量，$q_s$ 是对应的特征值。
\end{proof}

\subsection{利用特征多项式进行矩阵对角化}

要得到与矩阵 $A$ 相似的对角矩阵，我们需要找出 $A$ 的特征值 $\lambda_i$ 和特征向量 $\vec \alpha_i$。有了特征多项式，我们只需要找出 $A$ 的特征值 $\lambda_i$，并利用 $\vec \alpha_i$ 是齐次线性方程组 $(\lambda_i I - A) \vec x = \vec 0$ 的解求出 $\vec \alpha_i$（并验证 $\vec \alpha_i$ 是否线性无关）。于是可以将过程分成三步：
\begin{enumerate}
	\item 解多项式的零点 $|\lambda I_n - A| = 0$，得到 $n$ 个解 $\lambda_1, \ldots, \lambda_n$（包括重解）。
	\item 对于每个 $\lambda_i$，解齐次线性方程组 $(\lambda_i I - A) \vec x = \vec 0$。对于每个方程组，将任一基础解系作为它的解。将所有方程组的非零解合在一起构成包含 $n$ 个向量的列向量组。
	\item 检查列向量组 $\vec \alpha_1, \ldots, \vec \alpha_n$ 是否线性无关。
\end{enumerate}

如果以上步骤能顺利进行，那么 $\lambda_i$ 即为 $A$ 的一个特征值，$\vec \alpha_j$ 为 $A$ 属于 $\lambda_i$ 的一个特征向量。

\bigskip

下面以斐波那契数列 $a_n = a_{n - 1} + a_{n - 2}$ 为例，展示矩阵对角化的分析方法。

\begin{solve}
	用矩阵表示斐波那契数列的递推公式为：
	$$
	\begin{bmatrix} a_n \\ a_{n - 1}\end{bmatrix}
	=
	\begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}
	\begin{bmatrix} a_{n - 1} \\ a_{n - 2} \end{bmatrix}
	$$

	设 $A = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}$，下面对 $A$ 进行对角化。

	\begin{enumerate}
		\item 解方程 $|\lambda I - A| = 0$。
		$$
		\begin{vmatrix}\lambda I - A\end{vmatrix} =
		\begin{vmatrix} \lambda - 1 & -1 \\ -1 & \lambda \end{vmatrix} =
		\lambda^2 - \lambda - 1 = 0
		$$

		解得 $\lambda_1 = \dfrac{1 - \sqrt 5}{2}, \lambda_2 = \dfrac{1 + \sqrt 5}{2}$。

		\item 分别解关于 $\vec X$ 的方程组 $A \vec X = \lambda_1 \vec X$，$A \vec X = \lambda_2 \vec X$。

		分别移项，得 $(\lambda_1 I - A) \vec X = \vec 0$，$(\lambda_2 I - A) \vec X = \vec 0$。注意到，$\lambda_1 I - A = \begin{bmatrix} \lambda_1 - 1 & -1 \\ -1 & \lambda_1 \end{bmatrix}$，$\lambda_2 I - A = \begin{bmatrix} \lambda_2 - 1 & -1 \\ -1 & \lambda_2 \end{bmatrix}$，它们的行列式都为 $0$，而它们都不是零矩阵，故它们的解空间的维数为 $2 - 1 = 1$。于是，设 $\vec X_1$ 为 $(\lambda_1 I - A) \vec X = \vec 0$ 的基础解系，$\vec X_2$ 为 $(\lambda_2 I - A) \vec X = \vec 0$ 的基础解系。此处省略计算结果。

		\item 验证 $\vec X_1$ 和 $\vec X_2$ 线性无关。此处省略计算过程。
	\end{enumerate}

	最终可知，$A$ 可对角化，且满足：
	$$
	A \begin{bmatrix} \vec X_1 & \vec X_2 \end{bmatrix} = \begin{bmatrix} \vec X_1 & \vec X_2 \end{bmatrix} \begin{bmatrix} \dfrac{1 + \sqrt 5}{2} & 0 \\ 0 & \dfrac{1 - \sqrt 5}{2} \end{bmatrix}
	$$

	注意其中的 $\vec X_1, \vec X_2$ 是求解出的两个常向量。
\end{solve}

\subsection{特征子空间}

求解对角矩阵的三个步骤中，我们已经研究了第一步涉及的特征多项式。下面我们研究第二步中涉及到的齐次线性方程组的解空间，我们称其为特征子空间。

\begin{definition}{特征子空间}
	设 $\lambda_j$ 是 $A$ 的一个特征值，把齐次线性方程组 $(\lambda_j I - A) \vec x = \vec 0$ 的解空间称为 $A$ 的属于 $\lambda_j$ 的\emph{特征子空间}，其中的全部非零向量就是 $A$ 的属于 $\lambda_j$ 的全部特征向量。
\end{definition}

根据特征子空间的定义可知，对于 $A$ 的每一个特征值 $\lambda_j$，设齐次线性方程组 $(\lambda_j I - A) \vec x = \vec 0$ 的一个基础解系为 $\vec \eta_1, \ldots, \vec \eta_t$，则 $A$ 属于 $\lambda_j$ 的全部特征向量组成的集合是：
$$
\{ k_1 \vec \eta_1 + \cdots + k_t \vec \eta_t \colon k_1, \cdots, k_t \in \mathbb K, \text{不全为 $0$} \}
$$

\subsection{重数}

不难注意到，$|\lambda I - A| = 0$ 可能会有重根，我们自然会问属于某个重根的特征子空间满足什么性质。为此我们提出重数的概念。

\begin{definition}{代数重数,重数}
	设 $A$ 是数域 $\mathbb K$ 上的 $n$ 级矩阵，$\lambda_1$ 是 $A$ 的一个特征值。把 $\lambda_i$ 作为 $A$ 的特征多项式的根的重数 $l_i$ 叫做 $\lambda_i$ 的\emph{代数重数}，简称为\emph{重数}。
\end{definition}

\begin{definition}{几何重数}
	设 $A$ 是数域 $\mathbb K$ 上的 $n$ 级矩阵，$\lambda_1$ 是 $A$ 的一个特征值。把 $A$ 的属于 $\lambda_1$ 的特征子空间的维数叫做特征值 $\lambda_1$ 的\emph{几何重数}。
\end{definition}

设 $A$ 的一个特征值为 $\lambda_i$，其对应的特征子空间为：
$$
V_{\lambda_i} = \{\vec X \in \mathbb K^n \colon (\lambda_i I - A) \vec X = \vec 0\}
$$

则特征值 $\lambda_i$ 的几何重数为 $\dim V_{\lambda_i} = n - \operatorname{rank}(\lambda_i I -A)$\footnote{$\dim \operatorname{Ker} \phi = n - \operatorname{rank}(A)$}。

事实上，代数重数和几何重数具有如下关系。

\begin{theorem}
	设 $\lambda_1$ 是数域 $\mathbb K$ 上 $n$ 级矩阵 $A$ 的一个特征值，则 $\lambda_1$ 的几何重数不超过它的代数重数。
\end{theorem}

\begin{proof}[构造可逆矩阵 $P$]
	设 $A$ 的属于特征值 $\lambda_1$ 的特征子空间 $W_1$ 的维数为 $r$。在 $W_1$ 中取一个基 $\vec \alpha_1, \vec \alpha_2, \ldots, \vec \alpha_r$，把它扩充为 $\mathbb K^n$ 的一个基 $\vec \alpha_1, \vec \alpha_2, \ldots, \vec \alpha_r, \vec \beta_1, \ldots, \vec \beta_{n - r}$。把这 $n$ 个向量放进矩阵 $P$ 中，即：
	$$
	P = \begin{bmatrix} \vec \alpha_1 & \vec \alpha_2 & \cdots & \vec \alpha_r & \vec \beta_1 & \cdots & \vec \beta_{n - r} \end{bmatrix}
	$$

	这 $n$ 个向量线性无关，所以 $P$ 可逆。

	计算 $AP = \begin{bmatrix} A \vec \alpha_1 & \cdots & A \vec \alpha_r & A \vec \beta_1 & \cdots & A \vec \beta_{n - r} \end{bmatrix}$。其中，$A \vec \alpha_i = \lambda_1 \vec \alpha_i$，而 $A \vec \beta_i$ 是 $\vec \alpha_1, \ldots, \vec \alpha_r, \vec \beta_1, \ldots, \vec \beta_{n - r}$ 的线性组合，于是可以把 $AP$ 写成两个矩阵相乘的形式：
	$$
	\begin{aligned}
		AP =&
		\begin{bmatrix} \vec \alpha_1 & \vec \alpha_2 & \cdots & \vec \alpha_r & \vec \beta_1 & \cdots & \vec \beta_{n - r} \end{bmatrix} \cdot
		\\&
		\begin{bmatrix}
			\lambda_1 & 0 & \cdots & 0 & p_{11} & \cdots & p_{1, n - r}
			\\
			0 & \lambda_1 & \cdots & 0 & p_{21} & \cdots & p_{r, n - r}
			\\
			\vdots & \vdots & & \vdots & \vdots & & \vdots
			\\
			0 & 0 & \cdots & \lambda_1 & p_{r1} & \cdots & p_{r, n - r}
			\\
			0 & 0 & \cdots & 0 & q_{11} & \cdots & q_{1, n - r}
			\\
			0 & 0 & \cdots & 0 & q_{21} & \cdots & q_{2, n - r}
			\\
			\vdots & \vdots & & \vdots & \vdots & & \vdots
			\\
			0 & 0 & \cdots & 0 & q_{n - r, 1} & \cdots & q_{n - r, n - r}
		\end{bmatrix}
	\end{aligned}
	$$

	右侧矩阵写成分块矩阵为 $\begin{bmatrix} \lambda_1 I & \tilde P \\ 0 & \tilde Q \end{bmatrix}$。于是，$AP = P \begin{bmatrix} \lambda_1 I & \tilde P \\ 0 & \tilde Q \end{bmatrix}$。由于 $P$ 是可逆矩阵，所以 $A \sim \begin{bmatrix} \lambda_1 I & \tilde P \\ 0 & \tilde Q \end{bmatrix}$。由此可知 $A$ 的特征多项式与 $\begin{bmatrix} \lambda_1 I & \tilde P \\ 0 & \tilde Q \end{bmatrix}$ 的特征多项式相等。计算：
	$$
	|\lambda I - A| =
	\begin{vmatrix}
	(\lambda - \lambda_1) I_{r} & - \tilde P
	\\
	0 & \lambda I_{n - r} - \tilde Q
	\end{vmatrix}
	=
	(\lambda - \lambda_1)^{r} |\lambda I_{n - r} - \tilde Q|
	$$

	$|\lambda I_{n - r} - \tilde Q|$ 即 $Q$ 的特征多项式。其中可能有 $(\lambda - \lambda_1)$ 这个因数，也可能没有。设 $(\lambda - \lambda_1)$ 这个因数在特征多项式的幂次为 $l$，故 $r \le l$。
\end{proof}

\subsection{矩阵可对角化的条件}

通过尝试对角化以下矩阵，我们将总结出一系列判断矩阵是否可对角化的依据和相关定理。
$$
A = \begin{bmatrix} 0 & 1 & 2 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{bmatrix}
$$

\begin{solve}
	\begin{enumerate}
		\item 求特征多项式的零点。

		$$
		|\lambda I - A| = \begin{vmatrix} \lambda & -1 & -2 \\ 0 & \lambda & -1 \\ 0 & 0 & \lambda - 1 \end{vmatrix} = \lambda^2(\lambda - 1)
		$$

		可知 $A$ 的特征值为 $0$ 和 $1$，对应代数重数为 $2$ 和 $1$。

		\item 求特征向量。

		注意到，\textbf{代数重数为 $1$ 的特征值的几何重数一定为 $1$。因为 $\operatorname{rank} (\lambda_1 I - A) < n$，所以一定能找到属于它的特征向量，其几何重数不可能为 $0$}。而对于特征值 $0$，计算 $\operatorname{rank}(0 - A) = 2$，则 $\dim V_0 = 3 - 2 = 1$，即特征值 $0$ 对应的几何重数为 $1$。

		具体求解过程略。但可以知道，由于特征值 $0$ 的几何重数为 $1$，因而找不到两个线性无关的属于它的特征向量。因为无法找到三个线性无关的特征向量，所以 $A$ 不可对角化。

		\item 验证基础解系的并线性无关。

		由于第 2 步就已经失败，所以无法进行第 3 步。
	\end{enumerate}
\end{solve}

仍以尝试对角化三阶矩阵的过程为例，现在假设特征值 $1$ 的几何重数是 $1$，但特征值 $0$ 的几何重数为 $2$，我们能否因为两者之和等于 $3$ 而断言存在三个线性无关的特征向量？下述定理说明了这样断言的正确性。

\begin{theorem}
	设 $\lambda_1, \lambda_2$ 是数域 $\mathbb K$ 上 $n$ 级矩阵 $A$ 的不同的特征值，$\vec \alpha_1, \vec \alpha_2, \ldots, \vec \alpha_s$ 与 $\vec \beta_1, \vec \beta_2, \ldots, \vec \beta_r$ 分别是 $A$ 的属于 $\lambda_1, \lambda_2$ 的两组线性无关的特征向量，则 $\vec \alpha_1, \vec \alpha_2, \ldots, \vec \alpha_s, \vec \beta_1, \vec \beta_2, \ldots, \vec \beta_r$ 线性无关。
\end{theorem}

\begin{proof}[特征向量左乘 $A$]
	设：
	$$
	k_1 \vec \alpha_1 + \cdots + k_s \vec \alpha_s + l_1 \vec \beta_1 + \cdots + l_r \vec \beta_r = \vec 0
	$$

	两边左乘 $A$，有：
	$$
	A (k_1 \vec \alpha_1 + \cdots + k_s \vec \alpha_s + l_1 \vec \beta_1 + \cdots + l_r \vec \beta_r) = \vec 0
	$$

	由于这些向量都是特征向量，所以有：
	$$
	\lambda_1(k_1 \vec \alpha_1 + \cdots + k_s \vec \alpha_s) + \lambda_2(l_1 \beta_1 + \cdots + l_r \beta_r) = \vec 0
	$$

	已设：
	$$
	k_1 \vec \alpha_1 + \cdots + k_s \vec \alpha_s + l_1 \vec \beta_1 + \cdots + l_r \vec \beta_r = \vec 0
	$$

	上式乘以 $\lambda_1$ 后，得 $\lambda_1(k_1 \vec \alpha_1 + \cdots + k_s \vec \alpha_s) + \lambda_1(l_1 \vec \beta_1 + \cdots + l_r \vec \beta_r) = \vec 0$。两式相减可得：
	$$
	(\lambda_2 - \lambda_1)(l_1 \vec \beta_1 + \cdots + l_r \vec \beta_r) = \vec 0
	$$

	由于 $\vec \beta_1, \ldots, \vec \beta_r$ 线性无关，因而 $l_1 = \cdots = l_r = 0$ 是 $l_1, \ldots, l_r$ 的唯一解。代回原式，得 $k_1 \vec \alpha_1 + \cdots + k_s \vec \alpha_s = \vec 0$，由于 $\vec \alpha_1, \ldots, \vec \alpha_s$ 线性无关，因而 $k_1 = \cdots = k_s = 0$ 是 $k_1, \ldots, k_s$ 的唯一解，从而 $\vec \alpha_1, \ldots, \vec \alpha_s, \vec \beta_1, \ldots, \vec \beta_r$ 线性无关。
\end{proof}

归纳可得以下定理。

\begin{theorem}
	设 $\lambda_1, \lambda_2, \ldots, \lambda_m$ 是数域 $\mathbb K$ 上 $n$ 级矩阵 $A$ 的不同的特征值，$$\vec \alpha_{j1}, \vec \alpha_{j2}, \ldots, \vec \alpha_{j r_j}$$ 是 $A$ 的属于 $\lambda_j$ 的线性无关的特征向量，$j = 1, \ldots, m$，则向量组 $$\vec \alpha_{11},\ldots, \vec \alpha_{1 r_1}, \ldots, \vec \alpha_{m1}, \ldots, \vec \alpha_{m r_m}$$ 线性无关。
\end{theorem}

\bigskip

在引入了特征值和特征向量的概念后，我们可以再次提出矩阵可对角化的充分必要条件。

\begin{theorem}[矩阵可对角化的充分必要条件]
	数域 $\mathbb K$ 上 $n$ 级矩阵 $A$ 可对角化的充分必要条件是：

	\begin{enumerate}
		\item $A$ 有 $n$ 个线性无关的特征向量 $\vec \alpha_1, \ldots, \vec \alpha_n$，令 $P = \begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_n \end{bmatrix}$，有 $P^{-1} A P = \operatorname{diag} \{\lambda_1, \ldots, \lambda_n\}$。其中 $\lambda_i$ 是 $\vec \alpha_i$ 所属的特征值，$i = 1, \ldots, n$。

		\item $A$ 的属于不同特征值的特征子空间的维数之和等于 $n$。

		\item $A$ 的特征多项式的全部复根都属于 $\mathbb K$，并且 $A$ 的每个特征值的几何重数等于它的代数重数。
	\end{enumerate}
\end{theorem}

进一步，我们还能得到以下推论。

\begin{theorem}
	数域 $\mathbb K$ 上 $n$ 级矩阵 $A$ 如果有 $n$ 个不同的特征值，那么 $A$ 可对角化。
\end{theorem}

\begin{theorem}
	若 $A$ 的特征多项式有一个复根不属于数域 $\mathbb K$，或者 $A$ 有一个特征值的几何重数小于它的代数重数，则 $A$ 不可对角化。
\end{theorem}

在弄清了矩阵可对角化的充分必要条件后，我们可以提出相似标准形的概念。

\begin{definition}{相似标准形}
	若一个矩阵可对角化，则称与它相似的对角矩阵为它的\emph{相似标准形}。除了主对角线上元素的排列次序外，$A$ 的相似标准形是唯一的。
\end{definition}

\subsection{实对称矩阵的对角化}

\subsubsection{实对称矩阵的可对角化}

实数域上的对称矩阵简称为实对称矩阵。

\begin{theorem}
	实对称矩阵的特征多项式的每一个复根都是实数，从而它们都是特征值。
\end{theorem}

\begin{proof}
	设 $\lambda_0$ 是 $n$ 级实对称矩阵 $A$ 的特征多项式的任意一个复根，要证 $\lambda_0$ 是实数，只需证 $\lambda_0 = \overline \lambda_0$。下面在复数域上研究问题。设 $A \vec \alpha = \lambda_0 \vec \alpha$，已知 $A$ 的每个元素都是实数，即虚部为 $0$，于是等式两侧取共轭可得：
	$$
	A \overline{\vec \alpha} = \overline \lambda_0 \overline{\vec \alpha}
	$$
	注意 $A$ 是实对称矩阵，因此 $A = \overline A$。

	对于 $A \vec \alpha = \lambda_0 \vec \alpha$，取转置后得 $\vec \alpha' A = \lambda_0 \vec \alpha'$，再右乘 $\overline{\vec \alpha}$ 得 $\vec \alpha' A \overline{\vec \alpha} = \lambda_0 \vec \alpha' \overline{\vec \alpha}$。对于 $A \overline{\vec \alpha} = \overline \lambda_0 \overline{\vec \alpha}$，左乘 $\vec \alpha'$ 得 $\vec \alpha' A \overline{\vec \alpha} = \overline \lambda_0 \vec \alpha' \overline{\vec \alpha}$。

	注意到，现在有 $\vec \alpha' A \overline{\vec \alpha} = \lambda_0 \vec \alpha' \overline{\vec \alpha} = \overline \lambda_0 \vec \alpha' \overline{\vec \alpha}$，则可知 $(\overline \lambda_0 - \lambda_0) \vec \alpha' \overline{\vec \alpha} = 0$。由于 $\vec \alpha \ne 0$，所以 $\vec \alpha' \overline{\vec \alpha} \ne 0$，即一个非零向量与其共轭的内积不为 $0$。从而 $\overline \lambda_0 = \lambda_0$。
\end{proof}

\begin{theorem}
	实对称矩阵 $A$ 一定可对角化。并且若设 $A = T^{-1} D T$，则 $T$ 是正交矩阵。
\end{theorem}

\begin{proof}
	对实对称矩阵的级数 $n$ 作数学归纳法。当 $n = 1$ 时，显然成立。假设对于 $n - 1$ 级的实对称矩阵命题为真，下面证明对 $n$ 级实对称矩阵 $A$ 为真。

	实对称矩阵必有特征值，因此设 $A$ 的一个特征值为 $\lambda_1$、属于 $\lambda_1$ 的一个特征向量为 $\vec \eta_1$。并且规定 $|\vec \eta_1| = 1$（否则令 $\vec \eta_1 = \dfrac{\vec \eta_1}{|\vec \eta_1|}$）。

	把 $\vec \eta_1$ 扩充成 $\R^n$ 的一组标准正交基 $\vec \eta_1, \vec \eta_2, \cdots, \vec \eta_n$。令：
	$$
	T_1  = \begin{bmatrix} \vec \eta_1 & \vec \eta_2 & \cdots & \vec \eta_n \end{bmatrix}
	$$
	则 $T_1$ 是 $n$ 级正交矩阵。设：
	$$
	T_1^{-1} A T_1 = C
	$$

	左乘 $T_1$ 后得 $AT_1 = T_1 C$，展开记为 $\begin{bmatrix} A \vec \eta_1 & A \vec \eta_2 & \cdots & A \vec \eta_n \end{bmatrix} = T_1 C$。注意到有 $A\vec \eta_1 = \lambda_1 \vec \eta_1$，而 $\vec \eta_1$ 是 $T_1$ 的第一列，于是把 $C$ 写成分块矩阵为 $\begin{bmatrix} \lambda_1 & \vec \alpha \\ \vec 0 & B \end{bmatrix}$。

	另外注意到，$T_1$ 是正交矩阵，于是有 $T_1^{-1} = T'_1$。同时由于 $A$ 是实对称矩阵，于是有 $A = A'$。所以：
	$$
	T_1^{-1} A T_1 = \begin{bmatrix} \lambda_1 & \vec \alpha \\ \vec 0 & B \end{bmatrix} = T'_1 A T_1
	$$

	第二个等号两侧取转置，得：
	$$
	T'_1 A' T_1 = \begin{bmatrix} \lambda_1 & \vec 0 \\ \vec \alpha' & B' \end{bmatrix}
	$$

	而 $T'_1 A' T_1 = T_1^{-1} A T_1$，于是：
	$$
	\begin{bmatrix} \lambda_1 & \vec \alpha \\ \vec 0 & B \end{bmatrix} = \begin{bmatrix} \lambda_1 & \vec 0 \\ \vec \alpha' & B' \end{bmatrix}
	$$

	所以 $\vec \alpha = 0$，且 $B$ 是一个对称矩阵。由于 $A$ 是实对称矩阵，$T$ 是实矩阵，于是 $B$ 也是一个实对称矩阵。

	对 $B$ 进行归纳假设。可知存在 $n - 1$ 级正交矩阵 $T_2$，使得 $T_2^{-1} B T_2 = \operatorname{diag} \{\lambda_2, \ldots, \lambda_n\}$。令 $T = T_1 \begin{bmatrix} 1 & 0 \\ 0 & T_2 \end{bmatrix}$，由正交矩阵的乘积也是正交矩阵，可知 $T$ 也是正交矩阵。计算：
	$$
	\begin{aligned}
	T^{-1} AT &= \begin{bmatrix} 1 & \vec 0 \\ \vec 0 & T_2 \end{bmatrix}^{-1} T_1^{-1} A T_1 \begin{bmatrix} 1 & \vec 0 \\ \vec 0 & T_2 \end{bmatrix}
	\\&=
	\begin{bmatrix} 1 & \vec 0 \\ \vec 0 & T_2^{-1} \end{bmatrix}
	\begin{bmatrix} \lambda_1 & \vec 0 \\ \vec 0 & B \end{bmatrix}
	\begin{bmatrix} 1 & \vec 0 \\ \vec 0 & T_2 \end{bmatrix} \pod{T^{-1} = T', T_2^{-1} = T'_2}
	\\&=
	\begin{bmatrix} \lambda_1 & \vec 0 \\ \vec 0 & T_2^{-1} B T_2 \end{bmatrix}
	= \operatorname{diag}\{\lambda_1, \lambda_2, \cdots, \lambda_n\}
	\end{aligned}
	$$

	由数学归纳法，得证。
\end{proof}

以上证明方法直观易懂，但难以直接想出。下面给出几个定理和定义，以从几何的角度说明以上证明过程的思路。

\begin{theorem}
	对于 $n$ 级实矩阵 $A$，它是实对称矩阵的充分必要条件是：$\forall \vec \alpha, \vec \beta \in \R^n, (A \vec \alpha, \vec \beta) = (\vec \alpha, A \vec \beta)$。
\end{theorem}

\begin{proof}
	必要性。$(A \vec \alpha, \vec \beta) = (A \vec \alpha)^T \vec \beta = \vec \alpha^T A^T \vec \beta = \vec \alpha^T A \vec \beta = (\vec \alpha, A \vec \beta)$。

	充分性。已知 $\vec \alpha^T A^T \vec \beta = \vec \alpha^T A \vec \beta$。取 $\vec \alpha = \vec e_i, \vec \beta = \vec e_j$，则有 $A(i; j) = A^T(i; j)$，即可知 $A = A^T$。
\end{proof}

\begin{theorem}
	对于实对称矩阵 $A$，若 $A \vec \alpha = \lambda \vec \alpha$，则 $\forall \vec \beta \in \langle \vec \alpha \rangle^\perp, A \vec \beta \in \langle \vec \alpha \rangle^\perp$。
\end{theorem}

\begin{proof}
	要证明 $(A \vec \beta, \vec \alpha) = 0$。由于 $A$ 是一个实对称矩阵，所以 $(A \vec \beta, \vec \alpha) = (\vec \beta, A \vec \alpha)$，而 $A \vec \alpha = \lambda \vec \alpha$，因此 $(A \vec \beta, \vec \alpha) = \lambda(\vec \beta, \vec \alpha) = 0$。
\end{proof}

根据特征值与特征向量的定义式：
$$
A \vec \alpha = \lambda \vec \alpha
$$
我们可以写出一个映射：
$$
\begin{aligned}
	A \colon & \langle \vec \alpha \rangle \rightarrow \langle \vec \alpha \rangle
	\\&
	\vec x \mapsto A \vec x
\end{aligned}
$$

这意味着实对称矩阵 $A$ 对应的线性映射对于特征向量而言只是进行了一定比例的长度变化，而这个比例等于特征值。

在得出以上定理后，我们还可以写出一个映射：
$$
\begin{aligned}
	A \colon & \langle \vec \alpha \rangle^\perp \rightarrow \langle \vec \alpha \rangle^\perp
	\\&
	\vec x \mapsto A \vec x
\end{aligned}
$$

这意味着实对称矩阵 $A$ 总是将其特征向量张成的正交补 $\langle \vec \alpha \rangle^\perp$ 中的向量映射到 $\langle \vec \alpha \rangle^\perp$ 中。

\begin{theorem}
	对于实对称矩阵 $A$，设它的两个不同的特征值为 $\lambda, \mu$，对于非零向量 $\vec \alpha \in V_\lambda(A), \vec \beta \in V_\mu(A)$，有 $(\vec \alpha, \vec \beta) = 0$。
\end{theorem}

\begin{proof}
	由于 $(A \vec \alpha, \vec \beta) = (\vec \alpha, A \vec \beta)$，所以 $\lambda(\vec \alpha, \vec \beta) = \mu (\vec \alpha, \vec \beta)$，则 $(\vec \alpha, \vec \beta) = 0$。
\end{proof}

以上定理说明，实对称矩阵 $A$ 的属于不同特征值的特征向量是正交的。即对于非零向量 $\vec \alpha \in V_\lambda(A), \vec \beta \in V_\mu(A)$，必有 $\vec \alpha \in \bigl( V_\mu(A) \bigr)^\perp$。由于：
$$
\forall \vec \alpha \in V_\lambda(A), A \vec \alpha = \lambda \vec \alpha
$$

换句话说，对于特征值 $\lambda$，可以任取一个基础解系作为特征子空间的基，所以我们可以取一组标准正交基。

\begin{definition}{正交相似}
	对于 $n$ 级实矩阵 $A, B$，如果存在一个 $n$ 级正交矩阵 $T$，使得 $T^{-1} A T = B$，那么称 $A$ \emph{正交相似}于 $B$。
\end{definition}

由于特征子空间的基总可以取标准正交基，而实对称矩阵的不同特征值的特征向量是正交的，所以实对称矩阵若可以对角化，则一定正交相似于对角矩阵。

在实对称矩阵一定可对角化的证明中，事实上我们已经证明了实对称矩阵一定正交相似于对角矩阵。综上，该证明过程的一些思路可以总结如下：
\begin{enumerate}
	\item 求出一个特征值 $\lambda_1$，找到属于它的一个特征向量 $\vec \eta_1$，并归一化。
	\item 将 $\vec \eta_1$ 扩充为 $\R^n$ 的一组标准正交基。由于对于实对称矩阵 $A$ 的任一特征向量 $\vec \alpha$ 有 $\forall \vec \beta \in \langle \vec \alpha \rangle^\perp, A \vec \beta \in \langle \vec \alpha \rangle^\perp$，所以将这些标准正交基左乘 $A$。对于 $\vec \eta_1$，可得 $A \vec \eta_1 = \lambda_1 \vec \eta_1$，而对于其他标准正交基，仍然有 $A \vec \eta_i \in \langle \vec \alpha \rangle^\perp \pod{i \ne 1}$。
\end{enumerate}

\subsubsection{对角化实对称矩阵}

对于 $n$ 级实对称矩阵 $A$，找一个正交矩阵 $T$，使得 $T^{-1} A T$ 为对角矩阵的步骤如下：

\begin{enumerate}
	\item 计算 $|\lambda I - A|$，求出它的全部不同的根 $\lambda_1, \lambda_2, \ldots, \lambda_m$，它们是 $A$ 的全部特征值。
	\item 对于每一个特征值 $\lambda_j$，求 $(\lambda_j I - A) \vec x = \vec 0$ 的一个基础解系 $\vec \alpha_{j_1}, \vec \alpha_{j_2}, \ldots, \vec \alpha_{j_{r_j}}$。然后把它们施密特正交化和单位化，得到 $\vec \eta_{j1}, \vec \eta_{j2}, \ldots, \vec \eta_{j r_j}$。
	\item 令：
	$$
	T =
	\begin{bmatrix}
		\vec \eta_{11} & \cdots & \vec \eta_{1 r_1} & \cdots & \vec \eta_{m1} & \cdots & \vec \eta_{m r_m}
	\end{bmatrix}
	$$
	则 $T$ 是 $n$ 级正交矩阵，且：
	$$
	T^{-1} A T = \operatorname{diag} \{\underset{\text{$r_1$ 个}}{\underbrace{\lambda_1, \ldots, \lambda_1}}, \ldots, \underset{\text{$r_m$ 个}}{\underbrace{\lambda_m, \ldots, \lambda_m}}\}
	$$
\end{enumerate}

就以上过程而言，对角化实对称矩阵与对角化一般的矩阵没有差别，只是为了得到正交矩阵 $T$，需要额外进行施密特正交化和单位化。我们不禁会问：对于一般的矩阵 $A$，对各特征子空间的向量进行施密特正交化有意义吗？下面的定理否定了这样做的意义。

\begin{theorem}
	如果 $n$ 级实矩阵 $A$ 正交相似于一个对角矩阵 $D$，那么 $A$ 一定是实对称矩阵。
\end{theorem}

\begin{proof}
	由已知条件，有 $n$ 级正交矩阵 $T$，使 $T^{-1} AT = D$，从而：
	$$
	A' = (TDT^{-1})' = ({T'}^{-1} D' T') = TDT^{-1} = A
	$$

	所以 $A$ 是对称矩阵。
\end{proof}

可见，两个实矩阵相似，不意味着它们正交相似。例如，设 $n$ 级非对称实矩阵 $A$ 相似于一个对角矩阵 $D$，那么 $A$ 不能正交相似于 $D$，否则可得 $A$ 为对称矩阵，矛盾。由此可见，只有实对称矩阵才能正交相似于对角阵。

实对称矩阵之间的相似关系满足什么性质？下面的定理说明，实对称矩阵之间的相似一定是正交相似。

\begin{theorem}
	两个 $n$ 级实对称矩阵正交相似的充分必要条件是它们相似。
\end{theorem}

\begin{proof}
	必要性显然，下面证充分性。已知它们都正交相似于某一个对角阵。由于它们相似，它们的特征多项式相同，它们的特征值也相同，所以与它们正交相似的对角阵可以相同。由正交相似的对称性和传递性，可得 $A$ 正交相似于 $B$。
\end{proof}

可见，对于所有 $n$ 级实对称矩阵组成的集合来说，特征值（包括重数）是相似关系下的完全不变量。

\subsection{矩阵可对角化的等价命题}

前面已经给出了矩阵可对角化的三个等价命题：
\begin{enumerate}
	\item $A$ 有 $n$ 个线性无关的特征向量 $\vec \alpha_1, \ldots, \vec \alpha_n$，令 $P = \begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_n \end{bmatrix}$，有 $P^{-1} A P = \operatorname{diag} \{\lambda_1, \ldots, \lambda_n\}$。其中 $\lambda_i$ 是 $\vec \alpha_i$ 所属的特征值，$i = 1, \ldots, n$。

	\item $A$ 的属于不同特征值的特征子空间的维数之和等于 $n$。

	\item $A$ 的特征多项式的全部复根都属于 $\mathbb K$，并且 $A$ 的每个特征值的几何重数等于它的代数重数。
\end{enumerate}

下面，我们进一步研究特征子空间与可对角化的关系。首先给出一个有关线性子空间的引理。

\begin{theorem}
	设 $V_1, V_2$ 是 $\mathbb K^n$ 的线性子空间，则：
	$$
	\dim(V_1 + V_2) = \dim V_1 + \dim V_2 - \dim (V_1 \cap V_2)
	$$
\end{theorem}

\begin{proof}
	首先显然有 $(V_1 \cap V_2) \subset V_1, V_2$。取 $V_1 \cap V_2$ 的一组基 $\vec \alpha_1, \ldots, \vec \alpha_s$，将其扩充成 $V_1$ 的一组基：
	$$
	\vec \alpha_1, \ldots, \vec \alpha_s, \vec \beta_1, \ldots, \vec \beta_t
	$$

	又将 $\alpha_1, \ldots, \vec \alpha_s$ 扩充成 $V_2$ 的一组基：
	$$
	\vec \alpha_1, \ldots, \vec \alpha_s, \vec \gamma_1, \ldots, \vec \gamma_q
	$$

	显然，$V_1 + V_2$ 中的每一个元素都可由以下向量组线性表出：
	$$
	\vec \alpha_1, \ldots, \vec \alpha_s, \vec \beta_1, \ldots, \vec \beta_t, \vec \gamma_1, \ldots, \vec \gamma_q
	$$

	下面按定义证明这个向量组是线性无关的。设：
	$$
	\sum\limits_{i = 1}^s a_i \vec \alpha_i + \sum\limits_{j = 1}^t b_j \vec \beta_j + \sum\limits_{k = 1}^q c_k \vec \gamma_k = \vec 0
	$$

	移项得：
	$$
	\sum\limits_{i = 1}^s a_i \vec \alpha_i + \sum\limits_{j = 1}^t b_j \vec \beta_j = - \sum\limits_{k = 1}^q c_k \vec \gamma_k
	$$

	注意到，等式左侧的向量属于 $V_1$，等式右侧的向量属于 $V_2$，故等式两侧的向量都属于 $V_1 \cap V_2$。因此，等式右侧可表示为 $\vec \alpha_1, \ldots, \vec \alpha_s$ 的一个线性组合，于是设：
	$$
	\sum\limits_{k = 1}^q c_k \vec \gamma_k + \sum\limits_{i = 1}^s d_i \vec \alpha_i = \vec 0
	$$

	由于 $\vec \alpha_1, \ldots, \vec \alpha_s, \vec \gamma_1, \ldots, \vec \gamma_k$ 线性无关，所以：
	$$
	c_1 = \cdots = c_q = d_1 = \cdots = d_s = 0
	$$

	把 $c_1, \ldots, c_q$ 代入原式，同理可得：
	$$
	a_1 = \cdots = a_s = b_1 = \cdots = b_t = 0
	$$

	故 $\vec \alpha_1, \ldots, \vec \alpha_s, \vec \beta_1, \ldots, \vec \beta_t, \vec \gamma_1, \ldots, \vec \gamma_q$ 线性无关，它是 $V_1 + V_2$ 的一组基。
\end{proof}