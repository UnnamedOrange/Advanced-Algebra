% Licensed under the Creative Commons Attribution Share Alike 4.0 International.
% See the LICENCE file in the repository root for full licence text.

\section{$\R^n$ 的子空间的正交补}

\subsection{子空间的正交补与向量空间的分解}

给定 $\R^n$ 的一个子空间，我们想要知道，在 $\R^n$ 中有哪些向量与该子空间的所有向量都正交。为此，我们提出以下概念。

\begin{definition}{正交}
	设 $U$ 是欧几里得空间 $\R^n$ 的一个子空间，如果向量 $\vec \alpha$ 与 $U$ 中的每一个向量都正交，那么称 $\vec \alpha$ 与 $U$ \emph{正交}，记作 $\vec \alpha \perp U$。
\end{definition}

\begin{definition}{正交补}
	定义 $\R^n$ 的子空间 $U$ 的\emph{正交补} $U^\perp$ 为：
	$$
	U^\perp \triangleq \{ \vec \alpha \in \R^n \colon \vec \alpha \perp U \}
	$$
\end{definition}

可见，正交补即是上面的问题中要研究的对象。正交补满足什么性质？以下定理描述了正交补最基本的特征。

\begin{theorem}
	设 $U$ 是 $\R^n$ 的一个子空间，则 $U^\perp$ 也是 $\R^n$ 的一个子空间。
\end{theorem}

\begin{proof}
	由于 $\vec 0 \perp U$，因此 $\vec 0 \in U^\perp$，可知 $U^\perp$ 非空。任取 $\vec \alpha, \vec \beta \in U^\perp$，则 $\forall \vec \gamma \in U$，有：
	$$
	(\vec \alpha + \vec \beta, \vec \gamma) = (\vec \alpha, \vec \gamma) + (\vec \beta, \vec \gamma) = 0
	$$$$
	(k \vec \alpha, \vec \gamma) = k(\vec \alpha, \vec \gamma) = 0
	$$

	说明 $\vec \alpha + \vec \beta \in U^\perp$ 且 $k \vec \alpha \in U^\perp$，即 $U^\perp$ 是 $\R^n$ 的一个子空间。
\end{proof}

有了正交补的概念，我们能更好地描述 $\R^n$ 的结构，见以下定理。

\begin{theorem}
	设 $U$ 是 $\R^n$ 的一个子空间，则：
	$$
	U \cap U^\perp = \{ \vec 0\}
	$$
\end{theorem}

\begin{proof}
	由于 $U$ 是一个 $\mathbb K^n$ 的一个线性子空间，因此 $\vec 0 \in U$。前面已经证明，$\vec 0 \in U^\perp$。

	$\forall \vec v \in U^\perp \pod{\vec v \ne \vec 0}$，假设 $\vec v \in U$，那么由标准内积的正定性可知 $(\vec v, \vec v) > 0$（将左侧看作 $\vec v \in U^\perp$，将右侧看作 $\vec v \in U$），这与 $\forall w \in U, (\vec v, \vec w) = 0$ 矛盾，故 $\vec v \not \in U$。

	综上可得 $U \cap U^\perp = \{\vec 0\}$。
\end{proof}

\begin{theorem}
	设 $U$ 是 $\R^n$ 的一个子空间，则：
	$$
	\dim U + \dim U^\perp = \dim \R^n = n
	$$
\end{theorem}

\begin{proof}
	设 $U = \langle \vec \alpha_1, \ldots, \vec \alpha_s \rangle$，其中 $\vec \alpha_1, \ldots, \vec \alpha_s$ 线性无关（规定这些向量都是列向量）。对于 $\R^n$ 中的向量 $\vec \alpha$，易证：
	$$
	\vec \alpha \in U^\perp \Longleftrightarrow (\vec \alpha, \vec \alpha_i) = 0 \pod{i = 1, \ldots, s}
	$$

	于是 $\vec \alpha_i^T \vec \alpha = 0 \pod{i = 1, \ldots, s}$。将 $s$ 个这样的等式合在一起，可以得到：
	$$
	\begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_s \end{bmatrix}^T \vec \alpha = \vec 0
	$$

	即可知 $\vec \alpha$ 是齐次线性方程组 $\begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_s \end{bmatrix}^T \vec x = \vec 0$ 的一组解，所以有：
	$$
	U^\perp = \operatorname{Ker} \begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_s \end{bmatrix}^T
	$$

	由重要维数公式\footnote{$\dim \operatorname{Ker} \phi = n - \operatorname{rank}(A)$，其中 $A$ 是线性映射 $\phi$ 对应的矩阵，$n$ 是 $A$ 的列数。}：
	$$
	\begin{aligned}
		\dim U^\perp &= n - \operatorname{rank} \begin{bmatrix} \vec \alpha_1 & \cdots & \vec \alpha_s \end{bmatrix}^T
		\\&=
		n - s
	\end{aligned}
	$$
\end{proof}

更深刻地，我们有以下定理。我们首先提出一个引理。

\begin{theorem}
	对于实数域上的 $s \times n$ 矩阵，有：
	$$
	\operatorname{rank}(A^T A) = \operatorname{rank}(A) = \operatorname{rank}(AA^T)
	$$
\end{theorem}

\begin{proof}
	% TODO
\end{proof}

\begin{theorem}
	设 $\R^n$ 的一个子空间为 $U$，则 $\R^n$ 中的任何一个向量都可以唯一地表示为 $U$ 中的一个向量与 $U^\perp$ 中的一个向量的和，即 $\forall \vec \alpha \in \R^n, \exists \vec \beta \in U, \vec \gamma \in U^\perp$，使得 $\vec \alpha = \vec \beta + \vec \gamma$。
\end{theorem}

\begin{proof}
	% TODO
\end{proof}

以上定理提出了一种分解向量（或者说分解向量空间）的方法。顺着分解向量空间的思路，我们提出以下概念。

\begin{definition}{线性子空间的和}
	设 $V, W$ 都是 $\mathbb K^n$ 的线性子空间，定义它们的\emph{和} $V + W$ 为：
	$$
	V + W \triangleq \{\vec v + \vec w \colon \vec v \in V, \vec w \in W\}
	$$

	不难证明 $V + W$ 也是 $\mathbb K^n$ 的一个线性子空间。
\end{definition}

则根据以上定理，我们可以很容易地得出以下结论。

\begin{theorem}
	设 $\R^n$ 的一个子空间为 $U$，则：
	$$
	U + U^\perp = \R^n
	$$
\end{theorem}

\subsection{正交投影、正交基、正交矩阵}

\subsubsection{正交投影应用举例：线性方程组的最小二乘解}

